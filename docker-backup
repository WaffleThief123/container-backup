#!/usr/bin/env bash
# docker-backup - Pull-model backup orchestrator for Docker Compose services
#
# Runs on the BACKUP server, pulls from production over SSH.
#
# Usage:
#   docker-backup [OPTIONS]
#   docker-backup restore [OPTIONS]
#
# Options:
#   --config FILE     Path to global config (default: /opt/docker-backup/docker-backup.conf)
#   --service NAME    Back up only the named service
#   --dry-run         Walk through all steps without actually archiving/transferring
#   --no-prune        Skip GFS retention pruning
#   --no-notify       Skip webhook notification
#   -h, --help        Show this help
#
# Restore mode:
#   docker-backup restore --list [SERVICE]
#   docker-backup restore --file FILENAME [--target DIR]

set -euo pipefail

# --- Constants ---
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
DATE_STR=""  # set in run_backup from production server time
LOG_TAG="docker-backup"

# --- Defaults ---
CONFIG_FILE="/opt/docker-backup/docker-backup.conf"
SINGLE_SERVICE=""
DRY_RUN=false
NO_PRUNE=false
NO_NOTIFY=false

# Subcommand
SUBCOMMAND=""
RESTORE_LIST=false
RESTORE_FILE=""
RESTORE_TARGET=""

# --- Tracking ---
declare -a BACKUP_RESULTS=()
declare -a BACKUP_ERRORS=()
TOTAL_BACKUP_SIZE="0"
TOTAL_DURATION=0

# --- Logging ---
log_info()  { echo "[$(date +%H:%M:%S)] [INFO]  $*" | tee -a /dev/stderr | logger -t "$LOG_TAG" -p user.info 2>/dev/null || true; }
log_warn()  { echo "[$(date +%H:%M:%S)] [WARN]  $*" | tee -a /dev/stderr | logger -t "$LOG_TAG" -p user.warning 2>/dev/null || true; }
log_error() { echo "[$(date +%H:%M:%S)] [ERROR] $*" | tee -a /dev/stderr | logger -t "$LOG_TAG" -p user.err 2>/dev/null || true; }

# Format byte count as human-readable size (e.g., 1.2G, 340M, 56K).
# Uses stat -c%s which is reliable across GNU coreutils and BusyBox,
# unlike du -h which can silently fall back to raw block counts.
human_size() {
    local bytes="${1:-0}"
    if (( bytes >= 1073741824 )); then
        awk "BEGIN {printf \"%.1fG\", $bytes / 1073741824}"
    elif (( bytes >= 1048576 )); then
        awk "BEGIN {printf \"%.1fM\", $bytes / 1048576}"
    elif (( bytes >= 1024 )); then
        awk "BEGIN {printf \"%.1fK\", $bytes / 1024}"
    else
        echo "${bytes}B"
    fi
}

# --- Source library files ---
for lib in config database archive encrypt transfer retention notify restore; do
    lib_file="$SCRIPT_DIR/lib/${lib}.sh"
    if [[ -f "$lib_file" ]]; then
        # shellcheck source=/dev/null
        source "$lib_file"
    else
        echo "ERROR: Missing library: $lib_file" >&2
        exit 1
    fi
done

# --- Argument Parsing ---
parse_args() {
    while [[ $# -gt 0 ]]; do
        case "$1" in
            restore)
                SUBCOMMAND="restore"
                shift
                ;;
            --config)
                CONFIG_FILE="$2"
                shift 2
                ;;
            --service)
                SINGLE_SERVICE="$2"
                shift 2
                ;;
            --dry-run)
                DRY_RUN=true
                shift
                ;;
            --no-prune)
                NO_PRUNE=true
                shift
                ;;
            --no-notify)
                NO_NOTIFY=true
                shift
                ;;
            --list)
                RESTORE_LIST=true
                # Optional service filter
                if [[ ${2:-} ]] && [[ ! "$2" =~ ^-- ]]; then
                    SINGLE_SERVICE="$2"
                    shift
                fi
                shift
                ;;
            --file)
                RESTORE_FILE="$2"
                shift 2
                ;;
            --target)
                RESTORE_TARGET="$2"
                shift 2
                ;;
            -h|--help)
                usage
                exit 0
                ;;
            *)
                echo "Unknown option: $1" >&2
                usage >&2
                exit 1
                ;;
        esac
    done
}

usage() {
    cat <<'EOF'
Usage:
  docker-backup [OPTIONS]
  docker-backup restore --list [SERVICE]
  docker-backup restore --file FILENAME [--target DIR]

Backup options:
  --config FILE     Path to global config (default: /opt/docker-backup/docker-backup.conf)
  --service NAME    Back up only the named service
  --dry-run         Walk through all steps without archiving/transferring
  --no-prune        Skip GFS retention pruning
  --no-notify       Skip webhook notification
  -h, --help        Show this help

Restore options:
  --list [SERVICE]  List available backups (optionally filter by service)
  --file FILENAME   Restore a specific backup file
  --target DIR      Extract to DIR (default: /tmp/docker-backup-restore)
EOF
}

# --- Backup a single service ---
backup_service() {
    local service_dir="$1"
    local service_name
    service_name="$(basename "$service_dir")"

    log_info "=== Backing up: $service_name ==="

    local service_start
    service_start=$(date +%s)
    local service_error=false

    # Load per-service config from production
    load_service_config "$service_dir"

    # Detect compose file on production
    local compose_file=""
    compose_file="$(prod_ssh "find '${service_dir}' -maxdepth 1 \( -name docker-compose.yml -o -name docker-compose.yaml -o -name compose.yml -o -name compose.yaml \) | head -1" 2>/dev/null)" || true

    # Pre-backup hook (runs on production)
    if [[ -n "$PRE_BACKUP_HOOK" ]]; then
        log_info "Running pre-backup hook on production"
        if $DRY_RUN; then
            log_info "  [DRY RUN] Would run on production: $PRE_BACKUP_HOOK"
        else
            if ! prod_ssh "$PRE_BACKUP_HOOK"; then
                log_warn "Pre-backup hook failed (continuing)"
            fi
        fi
    fi

    # Stop containers if stop-start mode (on production)
    if [[ "$BACKUP_MODE" == "stop-start" ]]; then
        log_info "Stopping containers on production (stop-start mode)"
        if $DRY_RUN; then
            log_info "  [DRY RUN] Would run on production: docker compose -f $compose_file stop"
        else
            local compose_err
            if ! compose_err="$(prod_ssh "docker compose -f '$compose_file' stop" 2>&1)"; then
                log_error "Failed to stop containers: $compose_err"
                service_error=true
            fi
        fi
    fi

    # Database dumps (on production)
    if $DRY_RUN; then
        local db_defs
        db_defs="$(get_db_definitions)"
        if [[ -n "$db_defs" ]]; then
            log_info "[DRY RUN] Would dump databases on production:"
            while IFS='|' read -r container db_type db_names; do
                log_info "  $container ($db_type): $db_names"
            done <<< "$db_defs"
        fi
    else
        if ! dump_databases "$service_dir"; then
            log_error "Database dump errors occurred for $service_name"
            service_error=true
        fi
    fi

    # Create archive (on production, written to PRODUCTION_STAGING_DIR)
    local archive_name
    archive_name="$(archive_filename "$service_name" "$DATE_STR")"
    local created_archive=""

    if $DRY_RUN; then
        log_info "[DRY RUN] Would create archive on production: $archive_name"
        log_info "  Source: $service_dir"
        if [[ -n "$EXCLUDE" ]]; then
            log_info "  Excludes: $EXCLUDE"
        fi
    else
        if ! created_archive="$(create_archive "$service_dir" "$archive_name")"; then
            log_error "Archive creation failed for $service_name"
            service_error=true
            created_archive=""
        fi
    fi

    # Restart containers if stop-start mode (on production)
    if [[ "$BACKUP_MODE" == "stop-start" ]]; then
        log_info "Starting containers on production (stop-start mode)"
        if $DRY_RUN; then
            log_info "  [DRY RUN] Would run on production: docker compose -f $compose_file start"
        else
            local compose_err
            if ! compose_err="$(prod_ssh "docker compose -f '$compose_file' start" 2>&1)"; then
                log_error "Failed to start containers: $compose_err"
                service_error=true
            fi
        fi
    fi

    # Clean up database dumps on production
    if ! $DRY_RUN; then
        cleanup_dumps "$service_dir"
    fi

    # Post-backup hook (runs on production)
    if [[ -n "$POST_BACKUP_HOOK" ]]; then
        log_info "Running post-backup hook on production"
        if $DRY_RUN; then
            log_info "  [DRY RUN] Would run on production: $POST_BACKUP_HOOK"
        else
            if ! prod_ssh "$POST_BACKUP_HOOK"; then
                log_warn "Post-backup hook failed (continuing)"
            fi
        fi
    fi

    # Pull archive from production to local staging
    if [[ -n "$created_archive" ]] && ! $DRY_RUN; then
        if ! pull_archive "$created_archive" "$BACKUP_STAGING_DIR"; then
            log_error "Failed to pull archive for $service_name"
            service_error=true
        fi
    elif $DRY_RUN; then
        log_info "[DRY RUN] Would pull archive: $archive_name from production"
    fi

    # Encrypt locally and move to BACKUP_DIR
    local encrypted_name="${archive_name}.age"
    if [[ -n "$created_archive" ]] && [[ -f "$BACKUP_STAGING_DIR/$created_archive" ]]; then
        if encrypt_file "$BACKUP_STAGING_DIR/$created_archive" "$BACKUP_DIR/$encrypted_name" >/dev/null; then
            # Clean up local staging copy
            rm -f "$BACKUP_STAGING_DIR/$created_archive"
            # Clean up remote staging copy
            prod_ssh "rm -f '${PRODUCTION_STAGING_DIR}/${created_archive}'" 2>/dev/null
        else
            log_error "Encryption failed for $service_name"
            service_error=true
        fi
    elif $DRY_RUN; then
        log_info "[DRY RUN] Would encrypt: $archive_name -> $encrypted_name"
    fi

    # Track results
    local service_end
    service_end=$(date +%s)
    local service_duration=$((service_end - service_start))

    if $DRY_RUN; then
        BACKUP_RESULTS+=("$service_name: [DRY RUN] (${service_duration}s)")
    elif $service_error; then
        local size="N/A"
        if [[ -f "${BACKUP_DIR}/${encrypted_name}" ]]; then
            size="$(human_size "$(stat -c%s "${BACKUP_DIR}/${encrypted_name}" 2>/dev/null || echo 0)")"
        fi
        BACKUP_RESULTS+=("$service_name: ${size} (${service_duration}s) [ERRORS]")
        BACKUP_ERRORS+=("$service_name: check logs for details")
    else
        local size="unknown"
        if [[ -f "${BACKUP_DIR}/${encrypted_name}" ]]; then
            size="$(human_size "$(stat -c%s "${BACKUP_DIR}/${encrypted_name}" 2>/dev/null || echo 0)")"
        fi
        BACKUP_RESULTS+=("$service_name: ${size} (${service_duration}s)")
    fi

    log_info "=== Done: $service_name (${service_duration}s) ==="
    echo ""
}

# --- Main backup flow ---
run_backup() {
    local overall_start
    overall_start=$(date +%s)

    # Fetch timestamp from production server's local time
    DATE_STR="$(prod_ssh "date +%Y-%m-%d_%H%M%S" 2>/dev/null)" || DATE_STR="$(date +%Y-%m-%d_%H%M%S)"

    log_info "========================================="
    log_info "Docker Backup starting: $DATE_STR"
    log_info "Production: ${PRODUCTION_USER}@${PRODUCTION_HOST}"
    log_info "========================================="

    if $DRY_RUN; then
        log_info "*** DRY RUN MODE - no changes will be made ***"
        echo ""
    fi

    # Discover services on production
    local services
    if [[ -n "$SINGLE_SERVICE" ]]; then
        local service_path="$PRODUCTION_SOURCE_DIR/$SINGLE_SERVICE"
        local test_err
        if ! test_err="$(prod_ssh "test -d '$service_path'" 2>&1)"; then
            if [[ "$test_err" == *"Permission denied"* ]] || [[ "$test_err" == *"Connection"* ]] || [[ "$test_err" == *"resolve"* ]]; then
                log_error "Failed to connect to production server: $test_err"
            else
                log_error "Service directory not found on production: $service_path"
            fi
            exit 1
        fi
        services="$service_path"
    else
        services="$(discover_services "$PRODUCTION_SOURCE_DIR")"
    fi

    if [[ -z "$services" ]]; then
        log_error "No services found to back up"
        exit 1
    fi

    local service_count
    service_count="$(echo "$services" | wc -l)"
    log_info "Found $service_count service(s) to back up"
    echo ""

    # Create local directories and remote staging
    mkdir -p "$BACKUP_STAGING_DIR" "$BACKUP_DIR"
    if ! $DRY_RUN; then
        prod_ssh "mkdir -p '$PRODUCTION_STAGING_DIR'"
    fi

    # Back up each service
    while IFS= read -r service_dir; do
        [[ -z "$service_dir" ]] && continue
        backup_service "$service_dir"
    done <<< "$services"

    # Calculate total size of backup dir
    if [[ -d "$BACKUP_DIR" ]]; then
        TOTAL_BACKUP_SIZE="$(du -sh "$BACKUP_DIR" 2>/dev/null | cut -f1)"
    fi

    # GFS Pruning (local)
    if ! $NO_PRUNE && ! $DRY_RUN; then
        log_info "========================================="
        log_info "Applying retention policy"
        log_info "========================================="
        if ! apply_retention; then
            BACKUP_ERRORS+=("Retention: pruning failed")
        fi
        echo ""
    elif $DRY_RUN; then
        log_info "[DRY RUN] Would apply GFS retention (daily=$RETAIN_DAILY, weekly=$RETAIN_WEEKLY, monthly=$RETAIN_MONTHLY)"
    fi

    # Cleanup staging on both sides
    if ! $DRY_RUN; then
        log_info "Cleaning up staging directories"
        rm -rf "$BACKUP_STAGING_DIR"
        prod_ssh "rm -rf '$PRODUCTION_STAGING_DIR'" 2>/dev/null
    fi

    # Summary
    local overall_end
    overall_end=$(date +%s)
    TOTAL_DURATION=$((overall_end - overall_start))

    log_info "========================================="
    log_info "Backup complete in ${TOTAL_DURATION}s"
    log_info "Services: ${#BACKUP_RESULTS[@]}, Errors: ${#BACKUP_ERRORS[@]}"
    log_info "Total size: ${TOTAL_BACKUP_SIZE}"
    log_info "========================================="

    # Notify
    if ! $NO_NOTIFY; then
        build_summary
    fi

    # Exit with error if any errors occurred
    if [[ ${#BACKUP_ERRORS[@]} -gt 0 ]]; then
        return 1
    fi
    return 0
}

# --- Restore flow ---
run_restore() {
    if $RESTORE_LIST; then
        restore_list "$SINGLE_SERVICE"
        return $?
    fi

    if [[ -n "$RESTORE_FILE" ]]; then
        local target="${RESTORE_TARGET:-/tmp/docker-backup-restore}"
        restore_backup "$RESTORE_FILE" "$target"
        return $?
    fi

    echo "Restore mode requires --list or --file. See --help." >&2
    return 1
}

# --- Entry point ---
main() {
    parse_args "$@"

    # Load global config
    if [[ -f "$CONFIG_FILE" ]]; then
        load_global_config "$CONFIG_FILE"
    elif [[ -f "$SCRIPT_DIR/docker-backup.conf" ]]; then
        CONFIG_FILE="$SCRIPT_DIR/docker-backup.conf"
        load_global_config "$CONFIG_FILE"
    else
        echo "ERROR: Config file not found: $CONFIG_FILE" >&2
        echo "Tried: $CONFIG_FILE, $SCRIPT_DIR/docker-backup.conf" >&2
        exit 1
    fi

    case "$SUBCOMMAND" in
        restore)
            run_restore
            ;;
        "")
            run_backup
            ;;
        *)
            echo "Unknown subcommand: $SUBCOMMAND" >&2
            exit 1
            ;;
    esac
}

main "$@"
